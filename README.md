# Artigo da disciplina Sistemas de Apoio à Decisão

## A importância da limpeza de dados antes de usar algoritmos de predição
Este projeto destaca a relevância da limpeza de dados no processo de análise de dados, especialmente quando utilizamos algoritmos de predição.

## Motivação
Algoritmos de predição dependem de dados de entrada precisos para identificar padrões e gerar previsões confiáveis. Dados sujos — contendo erros, inconsistências ou valores ausentes — podem comprometer a eficácia desses algoritmos, levando a resultados imprecisos ou enviesados.

## O que é limpeza de dados?
A limpeza de dados é o processo de identificar e corrigir:

- Dados ausentes
- Valores duplicados
- Erros de digitação
- Outras inconsistências que afetam a qualidade do conjunto de dados.
## Exemplo prático

O famoso conjunto de dados Titanic: Machine Learning from Disaster, disponível no Kaggle, é um excelente caso prático. Este conjunto contém valores ausentes em variáveis como:

```Age```
```Cabin```
```Embarked```

Antes de treinar um modelo preditivo, é fundamental aplicar técnicas de limpeza para lidar com esses problemas e melhorar a qualidade dos dados.

## Objetivo do projeto

Este repositório explora:

1- A importância da limpeza de dados em projetos de machine learning.

2- Técnicas práticas para identificar e corrigir problemas em conjuntos de dados.

3- Exemplos práticos com Python, incluindo como tratar valores ausentes, duplicados e outros desafios encontrados em dados reais.
